{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32543613",
   "metadata": {},
   "source": [
    "# Using LLMs\n",
    "\n",
    "This Jupyter Notebook demonstrates the use of various Large Language Model (LLM) providers and tools for natural language processing tasks. It showcases how to interact with LLMs using the `crewai` library (which is used by Agentics), parse structured outputs with Pydantic models, and explore available LLM connections. The notebook provides practical examples for calling different LLMs, formatting responses, and integrating with external providers such as OpenAI and IBM WatsonX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62180815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.9 environment at: /Users/gliozzo/Code/agentics0.0.6/Agentics/.venv\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m249 packages\u001b[0m \u001b[2min 34ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2mUninstalled \u001b[1m2 packages\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m                                  \u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1magentics-py\u001b[0m\u001b[2m==0.0.4.post1.dev0+b2e926b (from file:///Users/gliozzo/Code/agentics0.0.6/Agentics)\u001b[0m\n",
      " \u001b[33m~\u001b[39m \u001b[1magentics-py\u001b[0m\u001b[2m==0.0.10\u001b[0m\n",
      "In Colab: False\n"
     ]
    }
   ],
   "source": [
    "! uv pip install agentics-py\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from getpass import getpass\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "CURRENT_PATH = \"\"\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "print(\"In Colab:\", IN_COLAB)\n",
    "\n",
    "\n",
    "if IN_COLAB:\n",
    "    CURRENT_PATH = \"/content/drive/MyDrive/\"\n",
    "    # Mount your google drive\n",
    "    load_dotenv(\"/content/drive/MyDrive/.env\")\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "else:\n",
    "    load_dotenv(find_dotenv())\n",
    "\n",
    "if not os.getenv(\"GEMINI_API_KEY\"):\n",
    "    os.environ[\"GEMINI_API_KEY\"] = getpass(\"Enter your GEMINI_API_KEY:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53d8ee7",
   "metadata": {},
   "source": [
    "## Connect to your own LLM provider\n",
    "Agentics uses CrewAI wrappers for main LLM providers. You can initialize your LLM as follows.\n",
    "[find out more](https://docs.crewai.com/en/concepts/llms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec92f07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<crewai.llm.LLM object at 0x10690bfb0>\n"
     ]
    }
   ],
   "source": [
    "from crewai import LLM\n",
    "\n",
    "# pick a provider (openai, anthropic, groq, etc.) - see crewai docs for details\n",
    "llm = LLM(model=\"gemini/gemini-2.0-flash\",\n",
    "    temperature=0.7,    # Adjust based on task\n",
    "    max_tokens=4096,    # Set based on output needs\n",
    "    timeout=300)        # Longer timeout for complex tasks\n",
    "\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617590f4",
   "metadata": {},
   "source": [
    "## Perform Simple LLM call\n",
    "\n",
    "Once an LLM is instatiated, you can perform LLM calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab039e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Eiffel Tower is located in **Paris, France**. More specifically, it's on the Champ de Mars, near the Seine River.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(llm.call(\"where is the eiffel tower located?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21fc4d0",
   "metadata": {},
   "source": [
    "## Perform Structured Call\n",
    "\n",
    "LLMs can generate structured objects given a pydantic schema if you instantiate them accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "984913a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"short_answer\": \"Pikachu\",\n",
      "  \"detailed_answer\": \"Pikachu is widely considered the most popular Pokémon. This is due to its prominent role as the mascot of the Pokémon franchise, its cute design, and its presence in various media, including the anime, games, and merchandise.\",\n",
      "  \"confidence\": 0.99\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "class Answer(BaseModel):\n",
    "    short_answer: str\n",
    "    detailed_answer: str\n",
    "    confidence: float\n",
    "\n",
    "struct_llm = LLM(model=\"gemini/gemini-2.0-flash\", response_format=Answer)\n",
    "\n",
    "print(struct_llm.call(\"Who is the most popular pokemon?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b53bbc",
   "metadata": {},
   "source": [
    "## Using Agentics Predefined LLMs\n",
    "\n",
    "Agentics has the following LLM handles: watsonx_llm, openai_llm, gemini_llm\n",
    "You can directly import and use them as defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4b95374",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-05 09:22:01.390 | DEBUG    | agentics.core.llm_connections:<module>:90 - AGENTICS is connecting to the following LLM API providers:\n",
      "2025-09-05 09:22:01.391 | DEBUG    | agentics.core.llm_connections:<module>:93 - 0 - WatsonX\n",
      "2025-09-05 09:22:01.391 | DEBUG    | agentics.core.llm_connections:<module>:98 - 1 - Gemini\n",
      "2025-09-05 09:22:01.391 | DEBUG    | agentics.core.llm_connections:<module>:102 - 2 - OpenAI\n",
      "2025-09-05 09:22:01.391 | DEBUG    | agentics.core.llm_connections:<module>:104 - Please add API keys in .env file to add or disconnect providers.\n",
      "2025-09-05 09:22:01.399 | DEBUG    | agentics.core.llm_connections:get_llm_provider:29 - No LLM provider specified. Using the first available provider.\n",
      "2025-09-05 09:22:01.399 | DEBUG    | agentics.core.llm_connections:get_llm_provider:31 - Available LLM providers: ['watsonx', 'gemini', 'openai']. Using 'watsonx'\n",
      "2025-09-05 09:22:01.401 | DEBUG    | agentics.core.llm_connections:get_llm_provider:29 - No LLM provider specified. Using the first available provider.\n",
      "2025-09-05 09:22:01.401 | DEBUG    | agentics.core.llm_connections:get_llm_provider:31 - Available LLM providers: ['watsonx', 'gemini', 'openai']. Using 'watsonx'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'watsonx': <crewai.llm.LLM object at 0x168c535c0>, 'gemini': <crewai.llm.LLM object at 0x13fb5e870>, 'openai': <crewai.llm.LLM object at 0x168c53740>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-05 09:22:02.819 | DEBUG    | agentics.core.llm_connections:get_llm_provider:38 - Using specified LLM provider: watsonx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rome is the capital city of Italy, located in the central region of the country, within the Lazio region. It is situated on the Tiber River and is about 30 kilometers inland from the Tyrrhenian Sea.\n",
      "Rome is the capital city of Italy, located in the central region of the country, within the Lazio region. It is situated on the Tiber River and is home to many historical landmarks, including the Colosseum and the Vatican City.\n"
     ]
    }
   ],
   "source": [
    "from agentics.core.llm_connections import available_llms, get_llm_provider\n",
    "print(available_llms)\n",
    "\n",
    "llm=get_llm_provider() ## get the default LLM provider from the available ones\n",
    "print(llm.call(\"Where is Rome?\"))\n",
    "\n",
    "llm=get_llm_provider(\"watsonx\") ## get a specific LLM provider from the available ones,change \"watsonx\" with \"openai\", \"gemini\", etc. as needed\n",
    "print(llm.call(\"Where is Rome?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211a8a36",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
