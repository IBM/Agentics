{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32543613",
   "metadata": {},
   "source": [
    "# Using LLMs\n",
    "\n",
    "This Jupyter Notebook demonstrates the use of various Large Language Model (LLM) providers and tools for natural language processing tasks. It showcases how to interact with LLMs using the `crewai` library (which is used by Agentics), parse structured outputs with Pydantic models, and explore available LLM connections. The notebook provides practical examples for calling different LLMs, formatting responses, and integrating with external providers such as OpenAI and IBM WatsonX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62180815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Colab: False\n"
     ]
    }
   ],
   "source": [
    "! uv pip install agentics-py\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from getpass import getpass\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "CURRENT_PATH = \"\"\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "print(\"In Colab:\", IN_COLAB)\n",
    "\n",
    "\n",
    "if IN_COLAB:\n",
    "    CURRENT_PATH = \"/content/drive/MyDrive/\"\n",
    "    # Mount your google drive\n",
    "    load_dotenv(\"/content/drive/MyDrive/.env\")\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "else:\n",
    "    load_dotenv(find_dotenv())\n",
    "\n",
    "if not os.getenv(\"GEMINI_API_KEY\"):\n",
    "    os.environ[\"GEMINI_API_KEY\"] = getpass(\"Enter your GEMINI_API_KEY:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53d8ee7",
   "metadata": {},
   "source": [
    "## Connect to your own LLM provider\n",
    "Agentics uses CrewAI wrappers for main LLM providers. You can initialize your LLM as follows.\n",
    "[find out more](https://docs.crewai.com/en/concepts/llms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec92f07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<crewai.llm.LLM object at 0x11053af60>\n"
     ]
    }
   ],
   "source": [
    "from crewai import LLM\n",
    "\n",
    "# pick a provider (openai, anthropic, groq, etc.) - see crewai docs for details\n",
    "llm = LLM(model=\"gemini/gemini-2.0-flash\",\n",
    "    temperature=0.7,    # Adjust based on task\n",
    "    max_tokens=4096,    # Set based on output needs\n",
    "    timeout=300)        # Longer timeout for complex tasks\n",
    "\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617590f4",
   "metadata": {},
   "source": [
    "## Perform Simple LLM call\n",
    "\n",
    "Once an LLM is instatiated, you can perform LLM calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab039e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Eiffel Tower is located in **Paris, France**.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(llm.call(\"where is the eiffel tower located?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21fc4d0",
   "metadata": {},
   "source": [
    "## Perform Structured Call\n",
    "\n",
    "LLMs can generate structured objects given a pydantic schema if you instantiate them accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "984913a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"short_answer\": \"Pikachu\",\n",
      "  \"detailed_answer\": \"Pikachu is widely considered the most popular Pokémon due to its prominent role in the anime series, its iconic design, and its status as the mascot of the Pokémon franchise.\",\n",
      "  \"confidence\": 0.95\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "class Answer(BaseModel):\n",
    "    short_answer: str\n",
    "    detailed_answer: str\n",
    "    confidence: float\n",
    "\n",
    "struct_llm = LLM(model=\"gemini/gemini-2.0-flash\", response_format=Answer)\n",
    "\n",
    "print(struct_llm.call(\"Who is the most popular pokemon?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b53bbc",
   "metadata": {},
   "source": [
    "## Using Agentics Predefined LLMs\n",
    "\n",
    "Agentics has the following LLM handles: watsonx_llm, openai_llm, gemini_llm\n",
    "You can directly import and use them as defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4b95374",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-05 07:22:08.246 | DEBUG    | agentics.core.llm_connections:<module>:90 - AGENTICS is connecting to the following LLM API providers:\n",
      "2025-09-05 07:22:08.247 | DEBUG    | agentics.core.llm_connections:<module>:93 - 0 - WatsonX\n",
      "2025-09-05 07:22:08.247 | DEBUG    | agentics.core.llm_connections:<module>:98 - 1 - Gemini\n",
      "2025-09-05 07:22:08.247 | DEBUG    | agentics.core.llm_connections:<module>:102 - 2 - OpenAI\n",
      "2025-09-05 07:22:08.247 | DEBUG    | agentics.core.llm_connections:<module>:104 - Please add API keys in .env file to add or disconnect providers.\n",
      "2025-09-05 07:22:08.255 | DEBUG    | agentics.core.llm_connections:get_llm_provider:29 - No LLM provider specified. Using the first available provider.\n",
      "2025-09-05 07:22:08.255 | DEBUG    | agentics.core.llm_connections:get_llm_provider:31 - Available LLM providers: ['watsonx', 'gemini', 'openai']. Using 'watsonx'\n",
      "2025-09-05 07:22:08.257 | DEBUG    | agentics.core.llm_connections:get_llm_provider:29 - No LLM provider specified. Using the first available provider.\n",
      "2025-09-05 07:22:08.257 | DEBUG    | agentics.core.llm_connections:get_llm_provider:31 - Available LLM providers: ['watsonx', 'gemini', 'openai']. Using 'watsonx'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'watsonx': <crewai.llm.LLM object at 0x137212e10>, 'gemini': <crewai.llm.LLM object at 0x1371af740>, 'openai': <crewai.llm.LLM object at 0x137213020>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-05 07:22:09.643 | DEBUG    | agentics.core.llm_connections:get_llm_provider:38 - Using specified LLM provider: watsonx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rome is the capital city of Italy, located in the central part of the country, within the Lazio region. It is situated on the Tiber River and is home to numerous historical landmarks, including the Colosseum and the Roman Forum.\n",
      "Rome is the capital city of Italy, located in the central region of the country, within the Lazio region. It is situated on the Tiber River and is about 30 kilometers inland from the Tyrrhenian Sea.\n"
     ]
    }
   ],
   "source": [
    "from agentics.core.llm_connections import available_llms, get_llm_provider\n",
    "print(available_llms)\n",
    "\n",
    "llm=get_llm_provider() ## get the default LLM provider from the available ones\n",
    "print(llm.call(\"Where is Rome?\"))\n",
    "\n",
    "llm=get_llm_provider(\"watsonx\") ## get a specific LLM provider from the available ones,change \"watsonx\" with \"openai\", \"gemini\", etc. as needed\n",
    "print(llm.call(\"Where is Rome?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211a8a36",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
